{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from pathvalidate import replace_symbol\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import numpy.matlib\n",
    "\n",
    "RAW_PATH = '../data/raw/'\n",
    "TEST_FANDOM = 'Star Wars: The Clone Wars (2008) - All Media Types'\n",
    "KUDO_FILE = RAW_PATH + replace_symbol(TEST_FANDOM) + '/kudos.csv'\n",
    "META_FILE = RAW_PATH + replace_symbol(TEST_FANDOM) + '/meta.csv'\n",
    "TEST_REBELS = 'Star Wars: Rebels'\n",
    "KUDO_REBELS = RAW_PATH + replace_symbol(TEST_REBELS) + '/kudos.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to go from csv to a scipy.sparse.csr_matrix. This code should be put into a preprocessing script w/in the pipelie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_path(fandom):\n",
    "    fandom_dir = replace_symbol(fandom)\n",
    "    data_path = os.path.join(\n",
    "        os.path.dirname(os.path.abspath(__file__)), RAW_PATH+fandom_dir)\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    os.chdir(data_path)\n",
    "\n",
    "#init_path(TEST_FANDOM)   \n",
    "#df = pd.read_csv(\"kudos.csv\")\n",
    "\n",
    "df_TCW = pd.read_csv(KUDO_FILE)\n",
    "df_REB = pd.read_csv(KUDO_REBELS)\n",
    "print(f\" df_TCW: {type(df_TCW)} df_REB: {df_REB}\")\n",
    "#print(f\"dims TCW: {df_TCW. })\n",
    "frames = [df_TCW, df_REB]\n",
    "df = pd.concat(frames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_works = len(df['work_id'].unique())\n",
    "num_users = len(df['user'].unique())\n",
    "data = np.zeros((num_works, num_users))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {'work_id':{}, 'user':{}}\n",
    "with open(KUDO_FILE, newline='') as csvfile:\n",
    "    interactions = csv.reader(csvfile, delimiter=',')\n",
    "    next(interactions)\n",
    "    for row in interactions:\n",
    "        indices['work_id'].setdefault(row[0], len(indices['work_id']))\n",
    "        indices['user'].setdefault(row[1], len(indices['user']))\n",
    "        data[indices['work_id'][row[0]]][indices['user'][row[1]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = sp.csr_matrix(data)\n",
    "print(type(sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_indices = {'work_id':{}, 'user':{}}\n",
    "inverted_indices['work_id'] = {v: k for k, v in indices['work_id'].items()}\n",
    "inverted_indices['user'] = {v: k for k, v in indices['user'].items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_indice = indices['work_id']['23657317']\n",
    "num_to_return = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "modelBPR = implicit.bpr.BayesianPersonalizedRanking(factors=50, verify_negative_samples=True)\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "modelBPR.fit(sparse_matrix)\n",
    "\n",
    "# find related items\n",
    "related_BPR = modelBPR.similar_items(work_indice, num_to_return)\n",
    "for suggestion in related_BPR:\n",
    "    work_id = inverted_indices['work_id'][suggestion[0]]\n",
    "    print(f\"http://www.archiveofourown.org/works/{work_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(META_FILE)\n",
    "df_meta = pd.read_csv(META_FILE)\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_meta.loc[df_meta['work_id'] == 23657317]\n",
    "x['title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_meta(related):\n",
    "    for work in related:\n",
    "        work_id = inverted_indices['work_id'][work[0]]\n",
    "        meta = df_meta.loc[df_meta['work_id'] == int(work_id)]\n",
    "        title = meta['title'].values[0]\n",
    "        print(f\"http://www.archiveofourown.org/works/{work_id}\\t{title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_meta(related_BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeData(model, modelname): \n",
    "\n",
    "    #this_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "    #my_file = os.path.join(this_folder, modelname)\n",
    "    # Its important to use binary mode \n",
    "    dbfile = open('../models/'+modelname+'.pkl', 'wb') \n",
    "      \n",
    "    # source, destination \n",
    "    pickle.dump(model, dbfile)                      \n",
    "    dbfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(modelname): \n",
    "    # for reading also binary mode is important \n",
    "    dbfile = open('../models/'+modelname+'.pkl', 'rb')      \n",
    "    db = pickle.load(dbfile) \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRecs(related):\n",
    "    for suggestion in related:\n",
    "        work_id = inverted_indices['work_id'][suggestion[0]]\n",
    "        print(f\"http://www.archiveofourown.org/works/{work_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeData(modelBPR, 'bpr270220')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickled_model = loadData('test')\n",
    "# find related items\n",
    "related_pickled = pickled_model.similar_items(work_indice, num_to_return)\n",
    "printRecs(related_pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeData(indices, 'indices270220')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondac5a35e885d9c4f8fb5dfcef0e8a90378"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
