{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archiveofourown.org/tags/%E0%B9%80%E0%B8%94%E0%B8%B7%E0%B8%AD%E0%B8%99%E0%B9%80%E0%B8%81%E0%B8%B5%E0%B9%89%E0%B8%A2%E0%B8%A7%E0%B9%80%E0%B8%94%E0%B8%B7%E0%B8%AD%E0%B8%99%20%7C%202%20Moons%20-%20Chiffon_Cake/works'\n",
    "url = 'https://archiveofourown.org/tags/221B%20-%20Vincent%20Starrett/works'\n",
    "url = 'https://archiveofourown.org/tags/Star%20Wars:%20The%20Clone%20Wars%20(2008)%20-%20All%20Media%20Types/works?page=3'\n",
    "url = 'https://archiveofourown.org/tags/Star%20Wars:%20The%20Clone%20Wars%20(2008)%20-%20All%20Media%20Types/works?page=4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers = {'user-agent' : header_info}\n",
    "req = requests.get(url)\n",
    "src = req.text\n",
    "soup = BeautifulSoup(src, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(work):\n",
    "    try:\n",
    "        summary = work.find('blockquote', class_='userstuff summary').text.replace(\"\\n\", \"\").strip()\n",
    "    except AttributeError as e:\n",
    "        summary = ''\n",
    "    return [summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(work):\n",
    "\n",
    "    result = work.find('h4', class_='heading').find_all('a')\n",
    "    work_id = result[0].get('href').strip('/works/')\n",
    "    title = result[0].text\n",
    "    \n",
    "    auth_list = []\n",
    "    header_text = work.find('h4', class_='heading').text\n",
    "    if \"Anonymous\" in header_text:\n",
    "        auth = \"Anonymous\"\n",
    "    else:\n",
    "        authors = work.find_all('a', rel='author')\n",
    "        for author in authors:\n",
    "            auth_list.append(author.text)\n",
    "        auth = str(auth_list).replace('[', '').replace(']', '')\n",
    "        \n",
    "    gift_list = []\n",
    "    for link in result:\n",
    "        href = link.get('href')\n",
    "        if 'gifts' in href:\n",
    "            gift_list.append(link.text)\n",
    "            \n",
    "    if len(gift_list) == 0:\n",
    "        gift = \"\"\n",
    "    else:\n",
    "        gift = str(gift_list).replace('[', '').replace(']', '')\n",
    "            \n",
    "    return [work_id, title, auth, gift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23423080', 'Serenity. Courage. Wisdom.', \"'Project0506'\", '']\n",
      "['23207791', 'Once I Called You Brother', \"'collegefangirl3791'\", '']\n",
      "['23422546', 'Short on rations', \"'CrazyGlitch'\", '']\n",
      "['23422501', \"The Jedi's Gambit\", \"'Wolveria'\", '']\n",
      "['23422474', 'Anakin, Ahsoka, and Hope', \"'LittleRaven'\", '']\n",
      "['22950946', 'In Duty, the Heart Dwells', \"'Gabby (Kirahsoka)'\", '']\n",
      "['23421685', 'A Moment in Your Eyes', \"'LacePendragon'\", '']\n",
      "['23191399', 'To Guard', \"'SolitaryPeak'\", '']\n",
      "['23140285', 'Pro Eo - [For Him]', \"'veravia'\", '']\n",
      "['23419177', 'Reporter Say What?', \"'ussihavelovedthestarstoofondly'\", '']\n",
      "['23419333', \"I've Served My Time In Hell\", \"'TheSleepingOne (SleepingNebula)'\", '']\n",
      "['23395861', 'Rose Gardens', \"'Shadowmatic'\", '']\n",
      "['15182750', 'Star Wars IX: The Fallen Knight', \"'AKyloDarkly83 (ksquared83)', 'KR Krause (ksquared83)'\", '']\n",
      "['23417848', 'Ahsokas Hurenleben', \"'Anonym187'\", '']\n",
      "['23416870', 'Ton monde', \"'Nours'\", '']\n",
      "['22833184', 'Reconciliation of the Past', \"'Aislynn092'\", '']\n",
      "['23251651', 'Glory and Honour', \"'dieFabuliererin'\", '']\n",
      "['22530445', 'Balance', \"'beamirang'\", '']\n",
      "['23416654', 'The Story of How...', \"'djh_one'\", '']\n",
      "['23415418', 'Limericks', \"'Petra'\", '']\n"
     ]
    }
   ],
   "source": [
    "works = soup.find_all(class_=\"work blurb group\")\n",
    "for work in works:\n",
    "    print(get_header(work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(meta):\n",
    "    '''\n",
    "    returns a list of lists, of\n",
    "    rating, category, fandom, pairing, characters, additional_tags\n",
    "    '''\n",
    "    tags = ['relationships', 'characters', 'freeforms']\n",
    "    return list(map(lambda tag: get_tag_info(tag, meta), tags))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_info(category, meta):\n",
    "    '''\n",
    "    given a category and a 'work meta group, returns a list of tags (eg, 'rating' -> 'explicit')\n",
    "    '''\n",
    "    try:\n",
    "        tag_list = meta.find_all(\"li\", class_=str(category))\n",
    "    except AttributeError as e:\n",
    "        return []\n",
    "    return [unidecode(result.text) for result in tag_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(work):\n",
    "    '''\n",
    "    returns a list of  \n",
    "    language, published, status, date status, words, chapters, comments, kudos, bookmarks, hits\n",
    "    '''\n",
    "    categories = ['language', 'words', 'chapters', 'collections', 'comments', 'kudos', 'bookmarks', 'hits'] \n",
    "    stats = []\n",
    "    for cat in categories:\n",
    "        try:\n",
    "            result = work.find(\"dd\", class_=cat).text\n",
    "        except:\n",
    "            result = ''\n",
    "        stats.append(result)\n",
    "    return stats\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_tags(work):\n",
    "    req_tags = work.find(class_='required-tags').find_all('a')\n",
    "    return [x.text for x in req_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fandoms(work):\n",
    "    fandoms = ''\n",
    "    try:\n",
    "        tag_list = work.find('h5', class_='fandoms heading').find_all('a')\n",
    "        fan_list = [x.text for x in tag_list]\n",
    "        fandoms = \", \".join(fan_list)\n",
    "        #return(list(map(lambda x: ', '.join(x), tag_list)))\n",
    "\n",
    "    except AttributeError as e:\n",
    "        return []\n",
    "    \n",
    "    return [fandoms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated(work):\n",
    "    try:\n",
    "        date = work.find('p', class_='datetime').text\n",
    "    except AttributeError as e:\n",
    "        date = ''\n",
    "    return [date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "print(x.strftime(\"%b%d%Y\"))\n",
    "scrape_date = datetime.datetime.now().strftime(\"%Y%b%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(work):\n",
    "    try:\n",
    "        series = work.find('ul', class_='series')\n",
    "        part = series.find('strong').text\n",
    "        s_name = series.find('a').text\n",
    "    except AttributeError as e:\n",
    "        part, s_name = '', ''\n",
    "    return [part, s_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(works):\n",
    "    \n",
    "    for work in works:\n",
    "        tags = get_tags(work)\n",
    "        req_tags = get_required_tags(work)\n",
    "        stats = get_stats(work)\n",
    "        header_tags = get_header(work)\n",
    "        fandoms = get_fandoms(work)\n",
    "        summary = get_summary(work)\n",
    "        updated = get_updated(work)\n",
    "        series = get_series(work)\n",
    "        header = ['work_id', 'title', 'author', 'gifted', 'rating', 'warnings', 'category', 'status', 'fandom', 'relationship', 'character', 'additional tags', 'summary','language', 'words', 'chapters', 'collections', 'comments', 'kudos', 'bookmarks', 'hits', 'series_part', 'series_name', 'updated', 'scrape_date']\n",
    "        row = header_tags + req_tags + fandoms + list(map(lambda x: ', '.join(x), tags)) + summary + stats + series + updated + [scrape_date]\n",
    "        print(f\"Row: {row[8]}\")\n",
    "        print(\"*****\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soup(url, i):\n",
    "    url = url+'?page='+str(i)\n",
    "    print(url)\n",
    "    #headers = {'user-agent' : header_info}\n",
    "    req = requests.get(url)\n",
    "    src = req.text\n",
    "    soup = BeautifulSoup(src, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://archiveofourown.org/tags/Star%20Wars:%20The%20Clone%20Wars%20(2008)%20-%20All%20Media%20Types/works'\n",
    "page_count = 1\n",
    "soup = load_soup(base_url, page_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages = int(soup.find('li', class_='next').find_previous('li').text)\n",
    "works = soup.find_all(class_=\"work blurb group\")\n",
    "scrape_page(works)\n",
    "while page_count < max_pages+1:\n",
    "    page_count += 1\n",
    "    #request page\n",
    "    #increase page_count\n",
    "    #if 404:\n",
    "    #break\n",
    "    #works = soup.find_all(class_=\"work blurb group\")\n",
    "    #scrap_page(works)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag1 = ['stuff1', 'morestuff1']\n",
    "tag2 = ['']\n",
    "tag3 = [['boop3'],['blep3']]\n",
    "collated = [tag1]+[tag2]+tag3\n",
    "print(collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'http://archiveofourown.org/works/'+str(22336816)+'/kudos'  \n",
    "url = 'http://archiveofourown.org/works/'+str(14737352)+'/kudos' \n",
    "#url = 'http://archiveofourown.org/works/'+str(22336817)+'/kudos' # 404\n",
    "headers = {'user-agent' : 'Homemade Bot; rebecca.sanjabi@gmail.com'}\n",
    "    \n",
    "req = requests.get(url, headers=headers)\n",
    "src = req.text\n",
    "soup = BeautifulSoup(src, 'html.parser')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kudos(soup):\n",
    "    try:\n",
    "        my_list = soup.find(id=\"kudos\").find_all('a')\n",
    "        secondary_list = [x.text for x in set(my_list)]\n",
    "        print(\"try\")\n",
    "    except AttributeError as e:\n",
    "        print(\"except\")\n",
    "        return []\n",
    "    else:\n",
    "        print(\"else\")\n",
    "        return secondary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = get_summary(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if req.status_code != 200:\n",
    "    print('Access Denied')\n",
    "my_kudo_list = get_kudos(soup)\n",
    "unique_list = sorted(my_kudo_list)\n",
    "for el in unique_list:\n",
    "    print(el)\n",
    "print(len(unique_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/swr_fanworks/fanworks_kudos2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#ax.set_xticklabels(['English', 'Polski','Russkii'])\n",
    "#ax.set_xlabel(metric + ' and Languages')\n",
    "ax.set_ylim([0, 100])\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.boxplot(df['user'].value_counts())\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('fig1.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['user']=='pepoluan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['work_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['user'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = [\"work_id\",\"user\"]\n",
    "df2=df.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('../data/swr_fanworks/fanworks_kudos2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(var, var2):\n",
    "    var = var + 3\n",
    "    var2 = var2/4\n",
    "    print(f\"Inside function var value: {var}\")\n",
    "    \n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 1\n",
    "var2 = 4\n",
    "print(f\"Prior to function var value: {var}\")\n",
    "my_func(var, var2)\n",
    "print(f\"Post function var value: {var}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign(list):\n",
    "  list = [0, 1]\n",
    "\n",
    "def append(list):\n",
    "  list.append(1)\n",
    "\n",
    "list = [0]\n",
    "print(list)\n",
    "reassign(list)\n",
    "print(list)\n",
    "append(list)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listA = [0]\n",
    "listB = listA\n",
    "listB.append(1)\n",
    "print(listA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('bmh')\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "pd.set_option(\"display.max_columns\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fanfics_metadata.csv')\n",
    "cols_with_missing = [col for col in df.columns if df[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].fillna('No Category Specified', inplace=True)\n",
    "df['relationship'].fillna('No Relationship Specified', inplace=True)\n",
    "df['character'].fillna('No Character Specified', inplace=True)\n",
    "df['additional tags'].fillna('No Additional Tags Specified', inplace=True)\n",
    "df['words'].fillna(0, inplace=True)\n",
    "df['comments'].fillna(0, inplace=True)\n",
    "df['kudos'].fillna(0, inplace=True)\n",
    "df['bookmarks'].fillna(0, inplace=True)\n",
    "df['hits'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kudos'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kudos'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['kudos'] != 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in docs:\n",
    "    for term in d:\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "        print(f\"term: {term} index: {index} indices: {indices} data: {data} vocab: {vocabulary}\")\n",
    "csr_matrix((data, indices, indptr), dtype=int).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = '255.255.255.255'\n",
    "str.replace('.', '[.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bitdf3c78cf64194a55a128d85384e140b3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
